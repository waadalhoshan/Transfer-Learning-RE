{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 1: Pre-trained BERT Model and Requirements Classification",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAFxK_jE1jPz"
      },
      "source": [
        "## Step 0: Importing the dataset & Importing the BERT model\n",
        "Import the selected requirement dataset to be ready for processing.\n",
        "Thenn, we'll import the BERT model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To9ENLU90WGl"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyoj29J24hPX"
      },
      "source": [
        "import pandas as pd\n",
        "data = 'https://github.com/waadalhoshan/datasets/raw/main/Promise_NFR_dataset_orginal.csv'\n",
        "dataset = pd.read_csv(data, delimiter = ';')\n",
        "\n",
        "labels_short = ['US', 'SE']\n",
        "labels_long =  ['Usability', 'Security']\n",
        "\n",
        "Requirement_Statements = []\n",
        "selected_class = 2\n",
        "original_classes = []\n",
        "for index, row in dataset.iterrows():\n",
        "  #original_classes.append(row['NFR'])\n",
        "  #Requirement_Statements.append(row['RequirementText'])\n",
        "  if row['class'] == labels_short[0]:\n",
        "    original_classes.append(labels_long[0])\n",
        "    Requirement_Statements.append(row['RequirementText'])\n",
        "  if row['class'] == labels_short[1]:\n",
        "    original_classes.append(labels_long[1])\n",
        "    Requirement_Statements.append(row['RequirementText'])\n",
        "\n",
        "df = pd.DataFrame({'class' : original_classes,\n",
        "                                'RequirementText' : Requirement_Statements}, \n",
        "                                columns=['class','RequirementText'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRc2L89hh1Tf"
      },
      "source": [
        "We can ask pandas how many sentences are labeled as \"positive\" (value 1) and how many are labeled \"negative\" (having the value 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGvcfcCP5xpZ"
      },
      "source": [
        "df['class'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_MO08_KiAOb"
      },
      "source": [
        "To use BERT model, we have three options provided by Transformers package:\n",
        "* distilbert-base-uncased or cased model\n",
        "* bert-based-uncased or cased model\n",
        "* bert-large-uncased or cased model\n",
        "More details about those models are found at https://huggingface.co/transformers/model_doc/bert.html\n",
        "However, there are other BERT models specefic for langauge or domain-of-use "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1InADgf5xm2"
      },
      "source": [
        "# For DistilBERT:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "# For BERTbase\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZDBMn3wiSX6"
      },
      "source": [
        "## Step 1: Preparing the Dataset for BERT\n",
        "Before we can hand our sentences to BERT, we need to tokenize the sentences in a compatible format with the BERT model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg82ndBA5xlN"
      },
      "source": [
        "tokenized = batch_1['RequirementText'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CVb_FBypVYJ"
      },
      "source": [
        "###Padding\n",
        "After tokenization, tokenized is a list of sentences -- each sentences is represented as a list of tokens. We want BERT to process our examples all at once (as one batch). It's just faster that way. For that reason, we need to pad all lists to the same size, so we can represent the input as one 2-d array, rather than a list of lists (of different lengths)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URn-DWJt5xhP"
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjg306wjjmL"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdi7uXo95xeq"
      },
      "source": [
        "np.array(padded).shape\n",
        "print(padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDZBsYSDjzDV"
      },
      "source": [
        "### Masking\n",
        "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K_iGRNa_Ozc"
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "print(attention_mask)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK-CQB9-kN99"
      },
      "source": [
        "## Step 2: Extract Features using BERT embeddings\n",
        "Now that we have our model and inputs ready, let's run our model!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39UVjAV56PJz"
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "print(input_ids)\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "print(last_hidden_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoCep_WVuB3v"
      },
      "source": [
        "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
        "\n",
        "We'll save those in the `features` variable, as they'll serve as the features to our logitics regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9t60At16PVs"
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()\n",
        "print(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VZVU66Gurr-"
      },
      "source": [
        "The labels indicating the class of each requirement goes now into the `labels` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD3fX2yh6PTx"
      },
      "source": [
        "labels = df['class']\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaoEvM2evRx1"
      },
      "source": [
        "## Step 3: Train The Classification Model with the BERT embeddings\n",
        "Let's now split our datset into a training set and testing set (even though we're using 2,000 sentences from the SST2 training set)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddAqbkoU6PP9"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
        "print(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9bhSJpcv1Bl"
      },
      "source": [
        "Then, we can dive into Logistic regression directly with the Scikit Learn default parameters, but sometimes it's worth searching for the best value of the C parameter, which determines regularization strength."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyEwr7yYD3Ci"
      },
      "source": [
        " parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        " grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        " grid_search.fit(train_features, train_labels)\n",
        "\n",
        "print('best parameters: ', grid_search.best_params_)\n",
        " print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCT9u8vAwnID"
      },
      "source": [
        "We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. `LogisticRegression(C=5.2)`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG-EVWx4CzBc"
      },
      "source": [
        "'''\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)\n",
        "lr_clf = svm.SVC()\n",
        "lr_clf.fit(train_features, train_labels)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "lr_clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "lr_clf.fit(train_features, train_labels)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "lr_clf = DecisionTreeClassifier(random_state=0)\n",
        "lr_clf.fit(train_features, train_labels)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lr_clf = LinearRegression()\n",
        "lr_clf.fit(train_features, train_labels)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "lr_clf = KNeighborsClassifier(n_neighbors=3)\n",
        "lr_clf.fit(train_features, train_labels)\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "lr_clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "lr_clf.fit(train_features, train_labels)\n",
        "'''\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "lr_clf = GaussianNB()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rUMKuVgwzkY"
      },
      "source": [
        "## Step 4: Evaluating Model\n",
        "So how well does our model do in classifying sentences? One way is to check the accuracy against the testing dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCoyxRJ7ECTA"
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75oyhr3VxHoE"
      },
      "source": [
        "How good is this score? What can we compare it against? Let's first look at a dummy classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnwgmqNG7i5l"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlzMNlmJrw3V"
      },
      "source": [
        "Reference: https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/"
      ]
    }
  ]
}